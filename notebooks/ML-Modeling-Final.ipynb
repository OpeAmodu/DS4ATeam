{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Data Using Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import joblib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\r\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umg_data = pd.read_csv('final_merged_data.csv')\n",
    "umg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a new outcome variable called popularity\n",
    "# For this variable a song is popular if it scores above 30 for spotify_popularity index\n",
    "umg_data.loc[umg_data['spotify_popularity'] > 50, 'popular'] = 'Yes'\n",
    "umg_data.loc[umg_data['spotify_popularity'] <= 50, 'popular'] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating an age variable\n",
    "# the age variable calculates the age of the song from today's date\n",
    "umg_data['original_release_date'] = pd.to_datetime(umg_data['original_release_date'])\n",
    "umg_data['today_date'] = date.today()\n",
    "umg_data['today_date'] = pd.to_datetime(umg_data['today_date'])\n",
    "umg_data['age'] = umg_data['today_date'].sub(umg_data['original_release_date'], axis=0)\n",
    "umg_data['age'] = (umg_data.age/np.timedelta64(1, 'D')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umg_data.columns\n",
    "umg_data_model = umg_data[[\n",
    "    'danceability', 'energy', 'key', 'loudness', 'speechiness', 'acousticness', \n",
    "         'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'age', 'popular'\n",
    "         ]]\n",
    "umg_data_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umg_data_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking distribution of popular and non-popular songs\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(umg_data_model['popular']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above chart, it looks like there is an unequal distribution of popular and non-popular songs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['danceability', 'energy', 'key', 'loudness', 'speechiness', 'acousticness', \n",
    "         'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'age']\n",
    "\n",
    "X = umg_data_model[features]\n",
    "y = umg_data_model['popular']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "#scaling the features\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print(result2)\n",
    "result3 = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the accuracy of our model is about 92 percent. The accuracy canbe misleading. For UMG, the usefulness of our model would be in predicting the few songs that have the potential to be popular. The model above does well in predicting None popular songs since they are the most in our data, but does poorly in predicting popular songs since they are rare. We need to improve to predict the rare popular songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying SMOTE to oversample rare class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.3)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "X,y = over.fit_resample(X,y)\n",
    "X,y = under.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining Knn model of Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "#scaling the features\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result2 = classification_report(y_test, y_pred)\n",
    "print('\\nClassification Report:')\n",
    "print(result2)\n",
    "result3 = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although our accuracy reduced, the precision level, recall and f1-score improved for the Rare popular songs. Now we can predict the Rare popular songs better than before. It would be instructive to try other models like decision trees using our newly resample data and see how well it does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperperameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the hyperparameter tuning phase, we will try to find the best leaf_size, n_neighbors, p and see how if we can find the optimal that can improve our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,25))\n",
    "p=[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparams = dict(leaf_size=leaf_size, n_neighbors = n_neighbors, p=p)\n",
    "\n",
    "#instantiating knn\n",
    "knn_2 = KNeighborsClassifier()\n",
    "\n",
    "# using gridsearch and doing 10 ten fold cross validation\n",
    "clf = GridSearchCV(knn_2, hyperparams, cv=10)\n",
    "\n",
    "#fitting model\n",
    "best_model = clf.fit(X,y)\n",
    "\n",
    "#Showing results\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4642  608]\n",
      " [1019 1537]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.88      0.85      5250\n",
      "         Yes       0.72      0.60      0.65      2556\n",
      "\n",
      "    accuracy                           0.79      7806\n",
      "   macro avg       0.77      0.74      0.75      7806\n",
      "weighted avg       0.79      0.79      0.79      7806\n",
      "\n",
      "Accuracy:  0.7915705867281578\n"
     ]
    }
   ],
   "source": [
    "## re-writing model using the new parameters\r\n",
    "knn = KNeighborsClassifier(n_neighbors=2, leaf_size=2, p=1)\r\n",
    "knn.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = knn.predict(X_test)\r\n",
    "\r\n",
    "result = confusion_matrix(y_test, y_pred)\r\n",
    "print(\"Confusion Matrix:\")\r\n",
    "print(result)\r\n",
    "result2 = classification_report(y_test, y_pred)\r\n",
    "print('\\nClassification Report:')\r\n",
    "print(result2)\r\n",
    "result3 = accuracy_score(y_test, y_pred)\r\n",
    "print(\"Accuracy: \", result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalKNNmodel.sav']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(knn, \"finalKNNmodel.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4642  608]\n",
      " [1019 1537]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.88      0.85      5250\n",
      "         Yes       0.72      0.60      0.65      2556\n",
      "\n",
      "    accuracy                           0.79      7806\n",
      "   macro avg       0.77      0.74      0.75      7806\n",
      "weighted avg       0.79      0.79      0.79      7806\n",
      "\n",
      "Accuracy:  0.7915705867281578\n"
     ]
    }
   ],
   "source": [
    "loaded_knn = joblib.load(\"finalKNNmodel.sav\")\r\n",
    "\r\n",
    "y_pred = loaded_knn.predict(X_test)\r\n",
    "\r\n",
    "result = confusion_matrix(y_test, y_pred)\r\n",
    "print(\"Confusion Matrix:\")\r\n",
    "print(result)\r\n",
    "result2 = classification_report(y_test, y_pred)\r\n",
    "print('\\nClassification Report:')\r\n",
    "print(result2)\r\n",
    "result3 = accuracy_score(y_test, y_pred)\r\n",
    "print(\"Accuracy: \", result3)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree/Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_decision_tree_classifier(X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 46)\n",
    "\n",
    "    dt_clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 50)\n",
    "    \n",
    "    #fit\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "\n",
    "    #predict\n",
    "    y_preds = dt_clf.predict(X_test)\n",
    "    y_preds_prob = dt_clf.predict_proba(X_test)\n",
    "    \n",
    "    #score\n",
    "    mat = confusion_matrix(y_test, y_preds)\n",
    "    print(mat)\n",
    "    print(sns.heatmap(mat, annot=True, cmap='bwr', linewidths=.5))\n",
    "    acc = accuracy_score(y_test, y_preds)\n",
    "    print(acc)\n",
    "\n",
    "    #For cross validation\n",
    "    print('')\n",
    "    cv_score = cross_val_score(dt_clf, X, y, cv=10)\n",
    "    print('*************CV Scores*************')\n",
    "    print(cv_score)\n",
    "    print(np.mean(cv_score))\n",
    "    \n",
    "    print('')\n",
    "    print('Sensitivity-Specificity')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    \n",
    "    spec = tn/(tn+fp)\n",
    "    sens = tp/(tp+fn)\n",
    "    \n",
    "    print(spec, sens)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_decision_tree_classifier(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest/Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_random_forest_classifier(X, y):\n",
    "   \n",
    "    #First let's create training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 46)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=1000, max_depth=None)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_preds = clf.predict(X_test)\n",
    "\n",
    "    mat = confusion_matrix(y_test, y_preds)\n",
    "    print(mat)\n",
    "    print(sns.heatmap(mat, annot=True, cmap='bwr', linewidths=.5))\n",
    "    acc = accuracy_score(y_test, y_preds)\n",
    "    print(acc)\n",
    "    \n",
    "    print('')\n",
    "    cv_score = cross_val_score(clf, X, y, cv=10)\n",
    "    print('*************CV Scores*************')\n",
    "    print(cv_score)\n",
    "    print(np.mean(cv_score))\n",
    "    \n",
    "    print('')\n",
    "    print('Sensitivity-Specificity')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    \n",
    "    spec = tn/(tn+fp)\n",
    "    sens = tp/(tp+fn)\n",
    "    \n",
    "    print(spec, sens)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_random_forest_classifier(X, y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a4ec5485fc52906d8a7c8fcf8f39da33ca1f06d93010ba644db5c2b15d734d1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}